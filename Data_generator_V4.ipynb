{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_generator_V3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IceOnDunes/speech-recognition/blob/main/Data_generator_V4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW1nWOCI5HQe"
      },
      "source": [
        "\"\"\" Classe Data generator pour génerer les données par batch durant l'apprentissage \"on the fly\" \n",
        "    code de classe inspiré de : https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
        "    Ajout de la partie pre-traitement (normalisation, calcul de spectrogramme, padding ...) \n",
        "\"\"\"\n",
        "from CTCModel import CTCModel as CTCModel\n",
        "from tensorflow.keras.optimizers  import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Dense, Input,BatchNormalization, Dropout, Activation, TimeDistributed, Activation, Bidirectional, LSTM\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import string\n",
        "import librosa\n",
        "from scipy.io import wavfile\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTX_otxg2Pyy"
      },
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, list_IDs,shuffle=False, batch_size=32, window_len=128,nfft=256,hop_len=127):\n",
        "        'Initialization'\n",
        "        self.list_IDs = list_IDs\n",
        "        self.hop_len = hop_len\n",
        "        self.batch_size = batch_size\n",
        "        self.nfft= nfft\n",
        "        self.window_len = window_len\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "        self.char_dict =  { ' ': 0,\n",
        "                            'a': 1,\n",
        "                            'b' : 2,\n",
        "                            'c' : 3,\n",
        "                            'd' : 4,\n",
        "                            'e' : 5,\n",
        "                            'f' : 6,\n",
        "                            'g' : 7,\n",
        "                            'h' : 8,\n",
        "                            'i' : 9,\n",
        "                            'j' : 10,\n",
        "                            'k' : 11,\n",
        "                            'l' : 12,\n",
        "                            'm' : 13,\n",
        "                            'n' : 14,\n",
        "                            'o' : 15,\n",
        "                            'p' : 16,\n",
        "                            'q' : 17,\n",
        "                            'r' : 18,\n",
        "                            's' : 19,\n",
        "                            't' : 20,\n",
        "                            'u' : 21,\n",
        "                            'v' : 22,\n",
        "                            'w' : 23,\n",
        "                            'x' : 24,\n",
        "                            'y' : 25,\n",
        "                            'z' : 26\n",
        "                            }\n",
        "                          \n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def get_data (self,data_IDs):\n",
        "      \"\"\"renvoie le son ainsi que son text associé normalisé \"\"\"\n",
        "\n",
        "      son = []\n",
        "      text = []\n",
        "\n",
        "      \"récuperer les characters de ponctuations\"\n",
        "      ponctuation_char = set(string.punctuation)\n",
        "\n",
        "      for d in data_IDs:\n",
        "          fe, audio = wavfile.read(d)\n",
        "          moyenne = audio.mean()\n",
        "          std = audio.std()\n",
        "          audio = (audio-moyenne) / std\n",
        "          son.append(audio)\n",
        "\n",
        "          text_path = d[:-8] + '.TXT'  # conversion chemin audio vers chemin text correspondant\n",
        "          txt = open( text_path, 'r')\n",
        "          ligne = txt.readline()\n",
        "\n",
        "\n",
        "          # normaliser les texts\n",
        "          result = ''.join([i for i in ligne if (not i.isdigit() and i not in ponctuation_char )]).lstrip().lower().replace(\"\\n\", '')\n",
        "          text.append(result)\n",
        "      return son, text\n",
        "\n",
        "\n",
        "    def get_padded_mel_spectro(self,audio, maxlen):\n",
        "        mel_spectro =np.log(np.absolute(librosa.stft(audio.astype(float),  n_fft= self.nfft,hop_length=self.hop_len, win_length=self.window_len)))\n",
        "        x_len = mel_spectro.shape[1]\n",
        "\n",
        "        padded_spectro = tf.keras.preprocessing.sequence.pad_sequences(mel_spectro,maxlen=maxlen, dtype='float', padding='post', truncating='post',value=float(255))\n",
        "        return padded_spectro, x_len\n",
        "\n",
        "    def extract_features(self, x_data_init):\n",
        "      #extract longest spectrogram length\n",
        "        mel_spectrogram = np.log(np.absolute(librosa.stft(max(x_data_init, key=len).astype(float),n_fft= self.nfft,hop_length=self.hop_len, win_length=self.window_len)))\n",
        "        x_max_length = mel_spectrogram.shape[1]\n",
        "        # x_max_length = 640\n",
        "        x_data = []\n",
        "        x_data_len = []\n",
        "\n",
        "        for i in range(len(x_data_init)):\n",
        "\n",
        "            padded_spectro, x_len = self.get_padded_mel_spectro(x_data_init[i], maxlen=x_max_length)\n",
        "\n",
        "            x_data.append(padded_spectro.T)\n",
        "            x_data_len.append(x_len) \n",
        "\n",
        "        #convert to array\n",
        "        data_input = np.array(x_data)\n",
        "        input_length = np.array(x_data_len)\n",
        "\n",
        "        return data_input,input_length\n",
        "\n",
        "#changer les noms\n",
        "    def encode_text(self, y_data_init):\n",
        "\n",
        "        y_max_length = len(max(y_data_init, key=len))\n",
        "        y_data = []\n",
        "        y_data_len = []\n",
        "\n",
        "        for i in range(len(y_data_init)):\n",
        "            encoded = []\n",
        "            for c in y_data_init[i]:\n",
        "                if c=='':\n",
        "                  # changer map char et ajouter en haut\n",
        "                    encoded.append(self.char_dict['<SPACE>'])\n",
        "                else:\n",
        "                  encoded.append(self.char_dict[c])\n",
        "\n",
        "            y_len = len(encoded)\n",
        "\n",
        "\n",
        "            for j in range(len(encoded), y_max_length):\n",
        "                    encoded.append(float(255))\n",
        "            y_data.append(encoded)\n",
        "            y_data_len.append(y_len)\n",
        "\n",
        "        # convert to array\n",
        "        y_data = np.array(y_data)\n",
        "        label_length = np.array(y_data_len)\n",
        "\n",
        "        return y_data, label_length\n",
        "\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "       # Generate data\n",
        "        x_data_init, y_data_init = self.get_data(list_IDs_temp)\n",
        "\n",
        "        #compute the spec frame of the longest audio\n",
        "        x_data, input_length = self.extract_features(x_data_init)\n",
        "        y_data, label_length = self.encode_text(y_data_init)\n",
        "\n",
        "        inputs = [x_data, y_data, input_length, label_length]\n",
        "        outputs = np.zeros([self.batch_size])\n",
        "        return inputs,outputs"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLskg_tCBdyh"
      },
      "source": [
        "def update_dataframe(csv_path):\n",
        "    ## enleve les colonnes dont on n'a pas besoin\n",
        "    data = pd.read_csv(csv_path)\n",
        "    data = data.dropna(subset=['filename'])\n",
        "    data = data.drop(['test_or_train', 'dialect_region', 'filename',\n",
        "                      'path_from_data_dir', 'is_audio', 'is_word_file',\n",
        "                      'is_phonetic_file', 'is_sentence_file',\n",
        "                      'speaker_id', 'index'], axis=1)\n",
        "\n",
        "    data = data[(data.is_converted_audio == True)]\n",
        "    data = data.reset_index(drop=True)\n",
        "    paths = list(data['path_from_data_dir_windows'])\n",
        "    return data,paths"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBgsKFiRCBwO",
        "outputId": "384b1d91-9bd3-481c-c615-d963b8f6288a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4nUBmPTtlAT"
      },
      "source": [
        "# !cp -r /content/drive/MyDrive/Speech_recognition_dataset  /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gn3NmR9DEYCq"
      },
      "source": [
        "#\n",
        "\n",
        "# drive.mount('/content/drive')\n",
        "train_csv = '/content/drive/MyDrive/Speech_recognition_dataset/train_data.csv' #path to train.csv\n",
        "path = '/content/drive/MyDrive/Speech_recognition_dataset/data/' #path to TIMIT data\n",
        "\n",
        "\n",
        "train_dataframe,train_path = update_dataframe(train_csv)\n",
        "\n",
        "train_path = [path + x.replace('\\\\', '/') for x in train_path]\n",
        "valid_path=train_path[4160:-12]\n",
        "train_path=train_path[0:4160]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvWlXFxdLpA5",
        "outputId": "e33b93e9-9eba-418c-807d-9395b2e6a686"
      },
      "source": [
        "print(len(train_path))\n",
        "print(len(valid_path))\n",
        "data_params = {'window_len' : 128,\n",
        "               'hop_len' : 127,\n",
        "               'nfft' : 256,\n",
        "               'batch_size' : 32,\n",
        "               'shuffle' : True\n",
        "               }\n",
        "\n",
        "print(\"Data Generation\")\n",
        "training_generator = DataGenerator(train_path[0:64], **data_params)\n",
        "validation_generator = DataGenerator(valid_path[0:64], **data_params)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4160\n",
            "448\n",
            "Data Generation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVCrv_cy1Tml"
      },
      "source": [
        "# !pip install keras_ctcmodel\n",
        "# x_data_init, y_data_init = training_generator.get_data(train_path[0:32])\n",
        "# x_data, input_length = training_generator.extract_features(x_data_init)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIICq6uvG7qz"
      },
      "source": [
        "# print(input_length)\n",
        "# print(x_data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJUcSMq7Brl4"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5fEk9DxBjox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03da8e89-d959-45dd-d856-2225b84be7ab"
      },
      "source": [
        "from tensorflow.keras.layers import Masking\n",
        "\n",
        "units=500\n",
        "nb_features=129\n",
        "optimizer = Adam(lr=0.0001)\n",
        "nb_labels=28\n",
        "\n",
        "x_input = Input((None,nb_features))\n",
        "x = Masking(mask_value=0)(x_input)\n",
        "print(x.shape)\n",
        "x = Bidirectional(LSTM(units,return_sequences=True))(x)\n",
        "print(x.shape)\n",
        "x = Bidirectional(LSTM(units,return_sequences=True))(x)\n",
        "print(x.shape)\n",
        "x = Bidirectional(LSTM(units, return_sequences=True))(x)\n",
        "print(x.shape)\n",
        "x = Bidirectional(LSTM(units,return_sequences=True))(x)\n",
        "print(x.shape)\n",
        "x = Bidirectional(LSTM(units,return_sequences=True))(x)\n",
        "print(x.shape)\n",
        "y_pred = TimeDistributed(Dense(units=nb_labels, activation='softmax'), name='softmax')(x)\n",
        "print(y_pred.shape)\n",
        "x_1 = tf.keras.Model(inputs=x_input, outputs= y_pred)\n",
        "x_1.summary()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, None, 129)\n",
            "(None, None, 1000)\n",
            "(None, None, 1000)\n",
            "(None, None, 1000)\n",
            "(None, None, 1000)\n",
            "(None, None, 1000)\n",
            "(None, None, 28)\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None, 129)]       0         \n",
            "                                                                 \n",
            " masking (Masking)           (None, None, 129)         0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, None, 1000)       2520000   \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, None, 1000)       6004000   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, None, 1000)       6004000   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, None, 1000)       6004000   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirectio  (None, None, 1000)       6004000   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " softmax (TimeDistributed)   (None, None, 28)          28028     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,564,028\n",
            "Trainable params: 26,564,028\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6YjMLxZksP9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13c9e57b-5998-4378-c524-1f5aedff4a86"
      },
      "source": [
        "# CTC\n",
        "\n",
        "model =CTCModel ([x_input], [y_pred])\n",
        "model.compile(optimizer=optimizer)\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, 129)]  0           []                               \n",
            "                                                                                                  \n",
            " masking (Masking)              (None, None, 129)    0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, None, 1000)   2520000     ['masking[0][0]']                \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirectional  (None, None, 1000)  6004000     ['bidirectional[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " bidirectional_2 (Bidirectional  (None, None, 1000)  6004000     ['bidirectional_1[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " bidirectional_3 (Bidirectional  (None, None, 1000)  6004000     ['bidirectional_2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " bidirectional_4 (Bidirectional  (None, None, 1000)  6004000     ['bidirectional_3[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " softmax (TimeDistributed)      (None, None, 28)     28028       ['bidirectional_4[0][0]']        \n",
            "                                                                                                  \n",
            " labels (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_length (InputLayer)      [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " label_length (InputLayer)      [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " CTCloss (Lambda)               (None, 1)            0           ['softmax[0][0]',                \n",
            "                                                                  'labels[0][0]',                 \n",
            "                                                                  'input_length[0][0]',           \n",
            "                                                                  'label_length[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 26,564,028\n",
            "Trainable params: 26,564,028\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuAXIQ4-7mlM"
      },
      "source": [
        "import os\n",
        "checkpoint_path = \"training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "            save_weights_only=True,\n",
        "            verbose=1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiVe5_9W2zrE",
        "outputId": "3c9e92d4-bad7-4adf-8b46-adc58c582737"
      },
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "  history=model.fit(training_generator,epochs=1,validation_data=validation_generator,callbacks=[cp_callback])\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - ETA: 0s - loss: 904.1401  \n",
            "Epoch 00001: saving model to training_1/cp.ckpt\n",
            "2/2 [==============================] - 114s 54s/step - loss: 904.1401 - val_loss: 292.4557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUz8Am1K2Ach"
      },
      "source": [
        "# # model.save('/content/drive/MyDrive/Speech_recognition_dataset/model_3')\n",
        "# import tensorflow as tf\n",
        "model.save_model('training_1')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeEv_4Rs2Pf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "38fe0e72-e5fe-45eb-a0f3-018ee51cb047"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print(history.history.keys())\n",
        "\n",
        "# summarize\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'val_loss'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRtcgIhVhGe-"
      },
      "source": [
        "test_csv = '/content/drive/MyDrive/Speech_recognition_dataset/test_data.csv' #path to test.csv\n",
        "path = '/content/drive/MyDrive/Speech_recognition_dataset/data/' #path to TIMIT data\n",
        "\n",
        "\n",
        "test_dataframe,test_path = update_dataframe(test_csv)\n",
        "\n",
        "test_path = [path + x.replace('\\\\', '/') for x in test_path]\n",
        "test_path=test_path[0:-4]\n",
        "\n",
        "test_generator = DataGenerator(test_path, **data_params)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddWuIxo85b8_"
      },
      "source": [
        "x_data_init, y_data_init = test_generator.get_data(test_path[0:4])\n",
        "\n",
        "#compute the spec frame of the longest audio\n",
        "x_data, input_length = test_generator.extract_features(x_data_init)\n",
        "y_data, label_length = test_generator.encode_text(y_data_init)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iuj28Tjki6tY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9f95ad7-7710-42c2-c0d5-b9069fbdd6ef"
      },
      "source": [
        "\n",
        "print(\"Evaluation\")\n",
        "model.save_model('/content/drive/MyDrive/Speech_recognition_dataset')\n",
        "from CTCModel import CTCModel as CTCModel\n",
        "model.evaluate([x_data, y_data, input_length, label_length],batch_size=32,metrics=['ler', 'ser'])\n",
        "\n",
        "\n",
        "\n",
        "# for i in range(10):  # print the 10 first predictions\n",
        "#     print(\"Prediction :\", [j for j in pred[i] if j!=-1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation\n",
            "1/1 [==============================] - 16s 16s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.88235295, 0.9117647 , 0.9302326 , 0.8888889 ], dtype=float32), 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6aHXhzPApnu"
      },
      "source": [
        "model.load_weights('/content/drive/MyDrive/Speech_recognition_dataset/model_weights.hdf5')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wUqBDtKSQCw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c2c5127-222f-48e1-e6ab-51953b3a1ebf"
      },
      "source": [
        "from CTCModel import CTCModel as CTCModel\n",
        "print(\"Prediction\")\n",
        "pred = model.predict([x_data, input_length],steps=1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEpRrK0vCjKC"
      },
      "source": [
        "pred = model.predict_generator(test_generator,steps=1)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kueIdzD5DCvG",
        "outputId": "eb8baf21-0d3c-42ec-a99a-125fbd7f3414"
      },
      "source": [
        "y_data[0:4,:]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 20.,   8.,   5.,   0.,   2.,  21.,  14.,   7.,   1.,  12.,  15.,\n",
              "         23.,   0.,  23.,   1.,  19.,   0.,  16.,  12.,   5.,   1.,  19.,\n",
              "          1.,  14.,  20.,  12.,  25.,   0.,  19.,   9.,  20.,  21.,   1.,\n",
              "         20.,   5.,   4.,   0.,  14.,   5.,   1.,  18.,   0.,  20.,   8.,\n",
              "          5.,   0.,  19.,   8.,  15.,  18.,   5., 255., 255., 255., 255.,\n",
              "        255., 255., 255., 255., 255., 255., 255., 255., 255., 255., 255.,\n",
              "        255., 255.],\n",
              "       [ 20.,   8.,   9.,  19.,   0.,   7.,  18.,  15.,  21.,  16.,   0.,\n",
              "          9.,  19.,   0.,  19.,   5.,   3.,  21.,  12.,   1.,  18.,   9.,\n",
              "         19.,  20.,   0.,   1.,  14.,   4.,   0.,  20.,   8.,   5.,   9.,\n",
              "         18.,   0.,  16.,  18.,  15.,   7.,  18.,   1.,  13.,   0.,  20.,\n",
              "          5.,  14.,   4.,  19.,   0.,  20.,  15.,   0.,   2.,   5.,   0.,\n",
              "         20.,   5.,   3.,   8.,  14.,  15.,  12.,  15.,   7.,   9.,   3.,\n",
              "          1.,  12.],\n",
              "       [  1.,   0.,   2.,   9.,   7.,   0.,   7.,  15.,   1.,  20.,   0.,\n",
              "          9.,   4.,  12.,  25.,   0.,   1.,  13.,   2.,  12.,   5.,   4.,\n",
              "          0.,  20.,   8.,  18.,  15.,  21.,   7.,   8.,   0.,  20.,   8.,\n",
              "          5.,   0.,   6.,   1.,  18.,  13.,  25.,   1.,  18.,   4., 255.,\n",
              "        255., 255., 255., 255., 255., 255., 255., 255., 255., 255., 255.,\n",
              "        255., 255., 255., 255., 255., 255., 255., 255., 255., 255., 255.,\n",
              "        255., 255.],\n",
              "       [  5.,   1.,  20.,   9.,  14.,   7.,   0.,  19.,  16.,   9.,  14.,\n",
              "          1.,   3.,   8.,   0.,  14.,   9.,   7.,   8.,  20.,  12.,  25.,\n",
              "          0.,   9.,  14.,   3.,  18.,   5.,   1.,  19.,   5.,  19.,   0.,\n",
              "         19.,  20.,  18.,   5.,  14.,   7.,  20.,   8.,   0.,  13.,   9.,\n",
              "         18.,   1.,   3.,  21.,  12.,  15.,  21.,  19.,  12.,  25., 255.,\n",
              "        255., 255., 255., 255., 255., 255., 255., 255., 255., 255., 255.,\n",
              "        255., 255.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3drOwecH_hHu",
        "outputId": "956de374-4c12-441c-be6f-9ced8b7083a9"
      },
      "source": [
        "len(pred[0][2])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PLvyXVFEgtz",
        "outputId": "69aa5896-9475-483c-b9d7-363fd82fc8a1"
      },
      "source": [
        "pred[1][0]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 20.,   8.,  15.,  19.,   5.,   0.,  23.,   5.,  18.,   5.,   0.,\n",
              "         5.,  19.,  16.,   5.,   3.,   9.,   1.,  12.,  12.,  25.,   0.,\n",
              "        20.,   8.,   5.,   0.,  15.,  14.,   5.,  19.,   0.,  20.,   8.,\n",
              "         1.,  20.,   0.,   1.,  12.,  12.,   0.,  15.,  20.,   8.,   5.,\n",
              "        18.,   0.,   7.,  18.,  15.,  23.,  14.,  21.,  16.,  19.,   0.,\n",
              "        12.,   1.,  21.,   7.,   8.,   5.,   4.,   0.,   1.,  20.,   0.,\n",
              "        12.,  15.,  21.,   4.,   5.,  19.,  20., 255., 255., 255., 255.])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh55-qc-GNjS"
      },
      "source": [
        "def decode(sequence):\n",
        "    unpaded = [j for j in sequence if j != -1]\n",
        "    pred = []\n",
        "    char_dict =  { ' ': 0,\n",
        "                            'a': 1,\n",
        "                            'b' : 2,\n",
        "                            'c' : 3,\n",
        "                            'd' : 4,\n",
        "                            'e' : 5,\n",
        "                            'f' : 6,\n",
        "                            'g' : 7,\n",
        "                            'h' : 8,\n",
        "                            'i' : 9,\n",
        "                            'j' : 10,\n",
        "                            'k' : 11,\n",
        "                            'l' : 12,\n",
        "                            'm' : 13,\n",
        "                            'n' : 14,\n",
        "                            'o' : 15,\n",
        "                            'p' : 16,\n",
        "                            'q' : 17,\n",
        "                            'r' : 18,\n",
        "                            's' : 19,\n",
        "                            't' : 20,\n",
        "                            'u' : 21,\n",
        "                            'v' : 22,\n",
        "                            'w' : 23,\n",
        "                            'x' : 24,\n",
        "                            'y' : 25,\n",
        "                            'z' : 26\n",
        "                            }\n",
        "    char_dict_inv= dict((v,k) for k,v in char_dict.items())\n",
        "    for c in unpaded:\n",
        "        if c == 0:\n",
        "            pred.append(\" \")\n",
        "        if c==255:\n",
        "          pred.append(\"\")\n",
        "        else:\n",
        "            pred.append(char_dict_inv[c])\n",
        "    pred = ''.join(pred)\n",
        "    return pred"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bVmXMK-AGPqq",
        "outputId": "3b86a809-4870-430a-af8e-810c213b0dc4"
      },
      "source": [
        "\n",
        "y_pred=decode(pred[0][0])\n",
        "y_pred"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'fbctfckkwkwkwkfwkckfwkkwkfwpw  '"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MP9r1lNfHqNs",
        "outputId": "2c732da9-bfcd-4415-f184-6d3615251acb"
      },
      "source": [
        "y_true=decode(pred[1][0])\n",
        "y_true"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'those  were  especially  the  ones  that  all  other  grownups  laughed  at  loudest'"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    }
  ]
}