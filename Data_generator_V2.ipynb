{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_generator_V2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IceOnDunes/speech-recognition/blob/main/Data_generator_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTX_otxg2Pyy"
      },
      "source": [
        "\"\"\" Classe Data generator pour génerer les données par batch durant l'apprentissage \"on the fly\" \n",
        "    code de classe inspiré de : https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
        "    Ajout de la partie pre-traitement (normalisation, calcul de spectrogramme, padding ...) \n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from CTCModel import CTCModel as CTCModel\n",
        "from tensorflow.keras.optimizers  import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Dense, Input,BatchNormalization, Dropout, Activation, TimeDistributed, Activation, Bidirectional, LSTM\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import string\n",
        "import librosa\n",
        "from scipy.io import wavfile\n",
        "\n",
        "\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, list_IDs,shuffle=False, batch_size=32, window_len=128,nfft=254,hop_len=127):\n",
        "        'Initialization'\n",
        "        self.list_IDs = list_IDs\n",
        "        self.hop_len = hop_len\n",
        "        self.batch_size = batch_size\n",
        "        self.nfft= nfft\n",
        "        self.window_len = window_len\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "        self.char_dict =  { 'a': 1,\n",
        "                            'b' : 2,\n",
        "                            'c' : 3,\n",
        "                            'd' : 4,\n",
        "                            'e' : 5,\n",
        "                            'f' : 6,\n",
        "                            'g' : 7,\n",
        "                            'h' : 8,\n",
        "                            'i' : 9,\n",
        "                            'j' : 10,\n",
        "                            'k' : 11,\n",
        "                            'l' : 12,\n",
        "                            'm' : 13,\n",
        "                            'n' : 14,\n",
        "                            'o' : 15,\n",
        "                            'p' : 16,\n",
        "                            'q' : 17,\n",
        "                            'r' : 18,\n",
        "                            's' : 19,\n",
        "                            't' : 20,\n",
        "                            'u' : 21,\n",
        "                            'v' : 22,\n",
        "                            'w' : 23,\n",
        "                            'x' : 24,\n",
        "                            'y' : 25,\n",
        "                            'z' : 26,\n",
        "                            ' ': 27}\n",
        "                          \n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def get_data (self,data_IDs):\n",
        "      \"\"\"renvoie le son ainsi que son text associé normalisé \"\"\"\n",
        "\n",
        "      son = []\n",
        "      text = []\n",
        "\n",
        "      \"récuperer les characters de ponctuations\"\n",
        "      ponctuation_char = set(string.punctuation)\n",
        "\n",
        "      for d in data_IDs:\n",
        "          fe, audio = wavfile.read(d)\n",
        "          moyenne = audio.mean()\n",
        "          std = audio.std()\n",
        "          audio = (audio-moyenne) / std\n",
        "          son.append(audio)\n",
        "\n",
        "          text_path = d[:-8] + '.TXT'  # conversion chemin audio vers chemin text correspondant\n",
        "          txt = open( text_path, 'r')\n",
        "          ligne = txt.readline()\n",
        "\n",
        "\n",
        "          # normaliser les texts\n",
        "          result = ''.join([i for i in ligne if (not i.isdigit() and i not in ponctuation_char )]).lstrip().lower().replace(\"\\n\", '')\n",
        "          text.append(result)\n",
        "      return son, text\n",
        "\n",
        "\n",
        "    def get_padded_mel_spectro(self,audio, maxlen):\n",
        "        mel_spectro =librosa.feature.melspectrogram(audio.astype(float),  n_fft= self.nfft,hop_length=self.hop_len, win_length=self.window_len)\n",
        "        x_len = mel_spectro.shape[1]\n",
        "\n",
        "        padded_spectro = tf.keras.preprocessing.sequence.pad_sequences(mel_spectro,maxlen=maxlen, dtype='float', padding='post', truncating='post')\n",
        "        return padded_spectro, x_len\n",
        "\n",
        "    def extract_features(self, x_data_init):\n",
        "      #extract longest spectrogram length\n",
        "        mel_spectrogram = librosa.feature.melspectrogram(max(x_data_init, key=len).astype(float),n_fft= self.nfft,hop_length=self.hop_len, win_length=self.window_len)\n",
        "        x_max_length = mel_spectrogram.shape[1]\n",
        "\n",
        "        x_data = []\n",
        "        x_data_len = []\n",
        "\n",
        "        for i in range(len(x_data_init)):\n",
        "\n",
        "            padded_spectro, x_len = self.get_padded_mel_spectro(x_data_init[i], maxlen=x_max_length )\n",
        "\n",
        "            x_data.append(padded_spectro)\n",
        "            x_data_len.append(x_len) \n",
        "\n",
        "        #convert to array\n",
        "        data_input = np.array(x_data)\n",
        "        input_length = np.array(x_data_len)\n",
        "\n",
        "        return data_input, input_length\n",
        "\n",
        "#changer les noms\n",
        "    def encode_text(self, y_data_init):\n",
        "\n",
        "        y_max_length = len(max(y_data_init, key=len))\n",
        "        y_data = []\n",
        "        y_data_len = []\n",
        "\n",
        "        for i in range(len(y_data_init)):\n",
        "            encoded = []\n",
        "            for c in y_data_init[i]:\n",
        "                if c=='':\n",
        "                  # changer map char et ajouter en haut\n",
        "                    encoded.append(self.char_dict['<SPACE>'])\n",
        "                else:\n",
        "                    encoded.append(self.char_dict[c])\n",
        "\n",
        "            y_len = len(encoded)\n",
        "\n",
        "\n",
        "            for j in range(len(encoded), y_max_length):\n",
        "                    encoded.append(float(0))\n",
        "            y_data.append(encoded)\n",
        "            y_data_len.append(y_len)\n",
        "\n",
        "        # convert to array\n",
        "        y_data = np.array(y_data)\n",
        "        label_length = np.array(y_data_len)\n",
        "\n",
        "        return y_data, label_length\n",
        "\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "       # Generate data\n",
        "        x_data_init, y_data_init = self.get_data(list_IDs_temp)\n",
        "\n",
        "        #compute the spec frame of the longest audio\n",
        "        x_data, input_length = self.extract_features(x_data_init)\n",
        "        y_data, label_length = self.encode_text(y_data_init)\n",
        "\n",
        "        inputs = [x_data, y_data, input_length, label_length]\n",
        "        outputs = np.zeros([self.batch_size])\n",
        "        return inputs, outputs"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLskg_tCBdyh"
      },
      "source": [
        "def update_dataframe(csv_path):\n",
        "    ## enleve les colonnes dont on n'a pas besoin\n",
        "    data = pd.read_csv(csv_path)\n",
        "    data = data.dropna(subset=['filename'])\n",
        "    data = data.drop(['test_or_train', 'dialect_region', 'filename',\n",
        "                      'path_from_data_dir', 'is_audio', 'is_word_file',\n",
        "                      'is_phonetic_file', 'is_sentence_file',\n",
        "                      'speaker_id', 'index'], axis=1)\n",
        "\n",
        "    data = data[(data.is_converted_audio == True)]\n",
        "    data = data.reset_index(drop=True)\n",
        "    paths = list(data['path_from_data_dir_windows'])\n",
        "    return data,paths"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gn3NmR9DEYCq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eaa4f6f-2c7e-4b9a-a23d-5b0a62e45dfd"
      },
      "source": [
        "#\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "train_csv = '/content/drive/MyDrive/Speech_recognition_dataset/train_data.csv' #path to train.csv\n",
        "path = '/content/drive/MyDrive/Speech_recognition_dataset/data/' #path to TIMIT data\n",
        "\n",
        "\n",
        "train_dataframe,train_path = update_dataframe(train_csv)\n",
        "\n",
        "train_path = [path + x.replace('\\\\', '/') for x in train_path]\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvWlXFxdLpA5",
        "outputId": "d4ab2b71-fa49-45fe-9be9-77ad728265d1"
      },
      "source": [
        "print(len(train_path))\n",
        "data_params = {'window_len' : 128,\n",
        "               'hop_len' : 127,\n",
        "               'nfft' : 256,\n",
        "               'batch_size' : 32,\n",
        "               'shuffle' : True\n",
        "               }\n",
        "\n",
        "print(\"Data Generation\")\n",
        "training_generator = DataGenerator(train_path[0:32], **data_params)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4620\n",
            "Data Generation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVCrv_cy1Tml"
      },
      "source": [
        "# !pip install keras_ctcmodel\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJUcSMq7Brl4"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5fEk9DxBjox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ec773bb-4f17-41a4-8552-1ae62da7f052"
      },
      "source": [
        "\n",
        "units=500\n",
        "nb_features=129\n",
        "optimizer = Adam(lr=0.0001)\n",
        "nb_labels=28\n",
        "\n",
        "x_input = Input((None, nb_features))\n",
        "x = Bidirectional(LSTM(units, return_sequences=True))(x_input)\n",
        "x = Bidirectional(LSTM(units, return_sequences=True))(x)\n",
        "x = Bidirectional(LSTM(units, dropout=0.5, return_sequences=True))(x)\n",
        "x = Bidirectional(LSTM(units, return_sequences=True))(x)\n",
        "x = Bidirectional(LSTM(units, return_sequences=True))(x)\n",
        "y_pred = TimeDistributed(Dense(units=nb_labels, activation='softmax'), name='softmax')(x)\n",
        "x_1 = tf.keras.Model(inputs=x_input, outputs= y_pred)\n",
        "x_1.summary()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, None, 129)]       0         \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirectio  (None, None, 1000)       2520000   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_6 (Bidirectio  (None, None, 1000)       6004000   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_7 (Bidirectio  (None, None, 1000)       6004000   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_8 (Bidirectio  (None, None, 1000)       6004000   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_9 (Bidirectio  (None, None, 1000)       6004000   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " softmax (TimeDistributed)   (None, None, 28)          28028     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,564,028\n",
            "Trainable params: 26,564,028\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6YjMLxZksP9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bbf764f-92aa-4179-cabe-05c77dd3cf2b"
      },
      "source": [
        "# CTC\n",
        "\n",
        "model =CTCModel ([x], [y_pred])\n",
        "model.compile(optimizer=optimizer)\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, None, 1000)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " softmax (TimeDistributed)      (None, None, 28)     28028       ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " labels (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_length (InputLayer)      [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " label_length (InputLayer)      [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " CTCloss (Lambda)               (None, 1)            0           ['softmax[2][0]',                \n",
            "                                                                  'labels[0][0]',                 \n",
            "                                                                  'input_length[0][0]',           \n",
            "                                                                  'label_length[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 28,028\n",
            "Trainable params: 28,028\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}