{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "F6hX918kaDn_"
   },
   "outputs": [],
   "source": [
    "from CTCModel import CTCModel as CTCModel\n",
    "from Model import model\n",
    "from fcts import update_dataframe,decode\n",
    "import matplotlib.pyplot as plt\n",
    "from Data_generator import DataGenerator\n",
    "from tensorflow.keras.optimizers  import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path='list_test_our_speech.csv'\n",
    "#csv_path='list_test.csv'\n",
    "\n",
    "test_path = pd.read_csv(csv_path, header=None)\n",
    "test_path=list(test_path[0])\n",
    "data_params = {'window_len' : 128,\n",
    "               'hop_len' : 127,\n",
    "               'nfft' : 256,\n",
    "               'batch_size' : len(test_path),\n",
    "               'shuffle' : False\n",
    "               }\n",
    "test_generator = DataGenerator(test_path, **data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zQ1F3KQqaTnA",
    "outputId": "a08a3159-b346-4c7e-f716-04fc467d6a26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, 129)\n",
      "(None, None, 1000)\n",
      "(None, None, 1000)\n",
      "(None, None, 1000)\n",
      "(None, None, 1000)\n",
      "(None, None, 1000)\n",
      "(None, None, 28)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Model training\n",
    "\n",
    "\"\"\"\n",
    "model = model()\n",
    "model.compile(optimizer=Adam(lr=0.0001))\n",
    "model.load_weights('saved-model_6-19-60.64.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DdMVxTM8aYoQ",
    "outputId": "ce674012-a9bf-4d4c-b908-3b9902e69026"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ISI\\S3\\Traitement_avance_du_son\\Projet\\Test_our_speech\\Data_generator.py:125: RuntimeWarning: divide by zero encountered in log\n",
      "  stft_spectrogram = np.log(np.absolute(librosa.stft(max(x_data_init, key=len).astype(float),n_fft= self.nfft,hop_length=self.hop_len, win_length=self.window_len)))\n",
      "E:\\ISI\\S3\\Traitement_avance_du_son\\Projet\\Test_our_speech\\Data_generator.py:113: RuntimeWarning: divide by zero encountered in log\n",
      "  stft_spectro =np.log(np.absolute(librosa.stft(audio.astype(float),  n_fft= self.nfft,hop_length=self.hop_len, win_length=self.window_len)))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Prediction\n",
    "\"\"\"\n",
    "print(\"Prediction\")\n",
    "pred = model.predict_generator(test_generator,steps=1)\n",
    "\"\"\"\n",
    "Decoding prediction results\n",
    "\"\"\"\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for i in range (len(pred[0])):\n",
    "    y_pred.append(decode(pred[0][i]))\n",
    "    y_true.append(decode(pred[1][i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aaK8YVorafYo",
    "outputId": "57c09d5e-6f96-46b0-eeb0-977691585695",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 1 )\n",
      "predicted :    \n",
      "Ground truth :  this  is  a  test  message  for  speech  to  text  project\n",
      "\n",
      "\n",
      "( 2 )\n",
      "predicted :    \n",
      "Ground truth :  the  watermelon  is  expensive\n",
      "\n",
      "\n",
      "( 3 )\n",
      "predicted :  m  womo    maroom  aooromo  mo  moo  moer\n",
      "Ground truth :  artificial  intelligence  is  very  useful  today\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Predictions Visualisation\n",
    "\"\"\"\n",
    "\n",
    "for i in range (len(test_path)):\n",
    "    print(\"(\",i+1,\")\")\n",
    "    y_pred=decode(pred[0][i])\n",
    "    print(\"predicted : \",y_pred)\n",
    "\n",
    "    y_true=decode(pred[1][i])\n",
    "\n",
    "    print(\"Ground truth : \",y_true)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path='list_test.csv'\n",
    "test_path = pd.read_csv(csv_path, header=None)\n",
    "test_path=list(test_path[0])\n",
    "test_generator2 = DataGenerator(test_path, **data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "( 1 )\n",
      "predicted :  she  had  your  dark  sui  in  greasy  wash  water  a  year\n",
      "Ground truth :  she  had  your  dark  suit  in  greasy  wash  water  all  year\n",
      "\n",
      "\n",
      "( 2 )\n",
      "predicted :  dnt  ask  me  to  cary  an  oily  rag  like  that\n",
      "Ground truth :  dont  ask  me  to  carry  an  oily  rag  like  that\n",
      "\n",
      "\n",
      "( 3 )\n",
      "predicted :  the  digraane  axes  wonley  ater  mouh  study\n",
      "Ground truth :  that  diagram  makes  sense  only  after  much  study\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Prediction\n",
    "\"\"\"\n",
    "print(\"Prediction\")\n",
    "pred = model.predict_generator(test_generator2,steps=1)\n",
    "\"\"\"\n",
    "Decoding prediction results\n",
    "\"\"\"\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for i in range (len(pred[0])):\n",
    "    y_pred.append(decode(pred[0][i]))\n",
    "    y_true.append(decode(pred[1][i]))\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "Predictions Visualisation\n",
    "\"\"\"\n",
    "\n",
    "for i in range (len(test_path)):\n",
    "    print(\"(\",i+1,\")\")\n",
    "    y_pred=decode(pred[0][i])\n",
    "    print(\"predicted : \",y_pred)\n",
    "\n",
    "    y_true=decode(pred[1][i])\n",
    "\n",
    "    print(\"Ground truth : \",y_true)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
